{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of dataset\n",
      "Size: 32269\n",
      "First 10 rows of corpus:\n",
      "\n",
      "0    [led, woody, andy's, toy, live, happily, room,...\n",
      "1    [sibling, judy, peter, discover, enchanted, bo...\n",
      "2    [family, wedding, reignites, ancient, feud, ne...\n",
      "3    [cheated, mistreated, stepped, woman, holding,...\n",
      "4    [george, bank, ha, recovered, daughter's, wedd...\n",
      "5    [obsessive, master, thief, neil, mccauley, lea...\n",
      "6    [ugly, duckling, undergone, remarkable, change...\n",
      "7    [mischievous, young, boy, tom, sawyer, witness...\n",
      "8    [international, action, superstar, jean, claud...\n",
      "9    [james, bond, must, unmask, mysterious, head, ...\n",
      "Name: corpus, dtype: object\n"
     ]
    }
   ],
   "source": [
    "movies_by_language = utils.get_dataset()\n",
    "\n",
    "overviews = movies_by_language[\"overview\"].tolist()\n",
    "titles = movies_by_language[\"title\"].tolist()\n",
    "poster_paths = movies_by_language[\"poster_path\"].tolist()\n",
    "\n",
    "corpus = movies_by_language[\"corpus\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pretrained word embeddings from GoogleNews:\n",
    "embeddings = api.load('word2vec-google-news-300', return_path=True)\n",
    "GN_word2vec = KeyedVectors.load_word2vec_format(embeddings, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training our corpus with GoogleNews embedding (CBOW architecture)\n",
    "cbow_model = Word2Vec(vector_size=300, window=5, min_count=2, workers=-1, sg=0) # sg=0 indicates CBOW architecture\n",
    "\n",
    "cbow_model.build_vocab(corpus)\n",
    "cbow_model.wv.vectors_lockf = np.ones(len(cbow_model.wv), dtype=np.float32)\n",
    "cbow_model.wv.intersect_word2vec_format(embeddings, lockf=1.0, binary=True)\n",
    "\n",
    "cbow_model.train(corpus, total_examples=cbow_model.corpus_count, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Word2Vec embeddings for each overview (CBOW architecture)\n",
    "\n",
    "embedded = utils.word_embeddings_vectorize(cbow_model, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(title):\n",
    "    input_idx = titles.index(title)\n",
    "    outputs = utils.word_embeddings_predict(embedded, input_idx, 5)\n",
    "\n",
    "    print(\"Top 5 movies most similar to\", title)\n",
    "    print(\"===================================\")\n",
    "\n",
    "    for index, value in outputs:\n",
    "        title = \"{} - Accuracy: {:.4f}\".format(titles[index], value)\n",
    "\n",
    "        try:\n",
    "            url = \"https://image.tmdb.org/t/p/original\" + poster_paths[index]\n",
    "            f = urllib.request.urlopen(url)\n",
    "        except urllib.request.HTTPError:\n",
    "            print(title)\n",
    "        else:\n",
    "            a = plt.imread(f)\n",
    "            plt.imshow(a)\n",
    "            \n",
    "            plt.title(title)\n",
    "            # print r.url, 'downloaded successfully'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movies most similar to  Toy Story\n",
      "===================================\n",
      "The Beautiful Beast - Accuracy: 0.7632\n",
      "Totally Awesome - Accuracy: 0.7618\n",
      "Motivational Growth - Accuracy: 0.7610\n",
      "VeggieTales: Duke and the Great Pie War - Accuracy: 0.7585\n",
      "Scooby-Doo! Stage Fright - Accuracy: 0.7583\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 5 movies most similar to  Deathline\n",
      "===================================\n",
      "Ninja: Shadow of a Tear - Accuracy: 0.8741\n",
      "The Stranger - Accuracy: 0.8527\n",
      "Gag - Accuracy: 0.8499\n",
      "B. Monkey - Accuracy: 0.8461\n",
      "Dead Hooker in a Trunk - Accuracy: 0.8451\n"
     ]
    }
   ],
   "source": [
    "title=\"GoldenEye\"\n",
    "predict(title)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "title=\"Deathline\"\n",
    "predict(title)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce93d1a4f56540fabf8f1c76c3aa6cf9757ad5e7d65f9c94603a0a68aa2226c4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
