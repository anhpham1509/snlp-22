{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (1.22.3)\n",
      "Requirement already satisfied: sklearn in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: nltk in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: joblib in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (from nltk) (8.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (from nltk) (4.61.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/jpturunen/miniconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy sklearn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/qtpzcp6j1q9_ldjr9z9tpgkms6z_vx/T/ipykernel_20068/2382365070.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_metadata = pd.read_csv(BASE_PATH + \"movies_metadata.csv\")\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = \"./dataset/\"\n",
    "# load dataset\n",
    "df_metadata = pd.read_csv(BASE_PATH + \"movies_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter columns\n",
    "metadata_cols = [\"id\", \"title\", \"overview\", \"tagline\", \"genres\", \"original_language\", \"poster_path\"]\n",
    "df_metadata   = df_metadata[metadata_cols]\n",
    "\n",
    "# sort by id\n",
    "df_metadata.sort_values(by=[\"id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter language\n",
    "in_english     = df_metadata[\"original_language\"] == \"en\"\n",
    "df_metadata_en = df_metadata[in_english]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/qtpzcp6j1q9_ldjr9z9tpgkms6z_vx/T/ipykernel_20068/1454195115.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_metadata_en[\"genres_parsed\"] = genre_names_joined\n",
      "/var/folders/69/qtpzcp6j1q9_ldjr9z9tpgkms6z_vx/T/ipykernel_20068/1454195115.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_metadata_en[\"document\"] = (\n"
     ]
    }
   ],
   "source": [
    "# parse names from genres column\n",
    "genre_names                     = list(map(lambda g: re.findall(\"'name':\\s*'(\\w*)'\", g), df_metadata_en[\"genres\"]))\n",
    "genre_names_joined              = list(map(lambda g: \" \".join(g), genre_names))\n",
    "df_metadata_en[\"genres_parsed\"] = genre_names_joined\n",
    "\n",
    "# combine features for tf-idf\n",
    "df_metadata_en[\"document\"] = (\n",
    "    df_metadata_en[\"title\"].astype(str) + \" \" + \n",
    "    df_metadata_en[\"overview\"].astype(str) + \" \" + \n",
    "    df_metadata_en[\"tagline\"].astype(str) + \" \" + \n",
    "    df_metadata_en[\"genres_parsed\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jpturunen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jpturunen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jpturunen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/jpturunen/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "lemmatizer = nltk.wordnet.WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# THIS CAN COME FROM TAGLINES\n",
    "stop_words.add(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df_metadata_en[\"document\"])\n",
    "vocab  = {}\n",
    "\n",
    "# clean corpus (remove stopwords, lemmatized etc.)\n",
    "for i, doc in enumerate(corpus):\n",
    "    as_lower     = doc.lower()\n",
    "    tokens       = word_tokenize(as_lower)\n",
    "    no_stopwords = [t for t in tokens if t not in stop_words]\n",
    "    lemmatized   = [lemmatizer.lemmatize(t) for t in no_stopwords]\n",
    "    corpus[i]    = \" \".join(lemmatized)\n",
    "    for t in lemmatized:\n",
    "        if t not in vocab:\n",
    "            vocab[t] = True\n",
    "            \n",
    "vocab = list(dict.keys(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TF-IDF\n",
      "sketchy      0.259745\n",
      "unwillingly  0.247252\n",
      "disgrace     0.238788\n",
      "barrel       0.220365\n",
      "             TF-IDF\n",
      "einstein   0.370590\n",
      "beer       0.304929\n",
      "invention  0.298064\n",
      "albert     0.296371\n",
      "           TF-IDF\n",
      "drake    0.360136\n",
      "hellcat  0.283237\n",
      "gray     0.219451\n",
      "flight   0.191834\n",
      "            TF-IDF\n",
      "customer  0.603979\n",
      "get       0.276022\n",
      "simone    0.243164\n",
      "mona      0.233355\n",
      "                  TF-IDF\n",
      "bloodwork       0.314088\n",
      "allergy         0.277276\n",
      "pharmaceutical  0.243626\n",
      "testing         0.226059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# calc tf-idf\n",
    "tf_idf_vec = TfidfVectorizer(lowercase=False, stop_words=None, vocabulary=vocab, smooth_idf=True, use_idf=True)\n",
    "tf_idf     = tf_idf_vec.fit_transform(corpus)\n",
    "\n",
    "# print first doc\n",
    "for i in range(5):    \n",
    "    df = pd.DataFrame(tf_idf[i].T.todense(), index=tf_idf_vec.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "    x = df.sort_values(\"TF-IDF\", ascending=False).head(4)\n",
    "    print(x)\n",
    "\n",
    "## TODO: genres not appearing as often as I would like... maybe the tf-idf value should then always be 1 for those tokens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# similarity matrix\n",
    "sim = cosine_similarity(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movies most similar to The Wolf of Wall Street:\n",
      "============================================\n",
      "- The Wolf of Wall Street\n",
      "- The Toast of New York\n",
      "- Wall Street: Money Never Sleeps\n",
      "- Wall Street\n",
      "- Wolves of Wall Street\n"
     ]
    }
   ],
   "source": [
    "titles      = list(df_metadata_en[\"title\"])\n",
    "movie_title = \"GoldenEye\"\n",
    "movie_idx   = titles.index(movie_title)\n",
    "top_5_sim   = list(sim[movie_idx].argsort()[::-1][:5])\n",
    "\n",
    "print(f\"Top 5 movies most similar to {movie_title}:\")\n",
    "print(\"============================================\")\n",
    "for i in top_5_sim:\n",
    "    print(f\"- {titles[i]}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
